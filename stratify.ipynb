{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"collapsed":true},"cell_type":"code","source":"import os\nos.environ['CUDA_VISIBLE_DEVICES']='0'\nimport sys\nimport warnings\nimport gc\nimport random\nimport numpy as np\nrandom.seed(31)\nnp.random.seed(23)\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nfrom itertools import chain\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.color import rgb2gray\nfrom skimage.morphology import label\nfrom scipy import ndimage as ndi\nimport zipfile\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, Dropout, BatchNormalization, Add, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Activation, ZeroPadding2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\n\nimport tensorflow as tf\nconfig = tf.ConfigProto()\nconfig.gpu_options.allow_growth = True\nsession = tf.Session(config=config)\nK.set_session(session)\n\n# Set some parameters\nBS = 32\nEPOCHS_1 = 100\nEPOCHS_2 = 100\nORI_D = 101\nTRAIN_ZIP = '../input/train.zip'\nTEST_ZIP = '../input/test.zip'\nTRAIN_PATH = '../input/train/'\nTEST_PATH = '../input/test/'\nTRAIN_CSV = '../input/train.csv'\nDEPTH_CSV = '../input/depths.csv'\n\nif not os.path.exists(TRAIN_PATH):\n    zip_ref = zipfile.ZipFile(TRAIN_ZIP, 'r')\n    zip_ref.extractall(TRAIN_PATH)\n    zip_ref.close()\nif not os.path.exists(TEST_PATH):\n    zip_ref = zipfile.ZipFile(TEST_ZIP, 'r')\n    zip_ref.extractall(TEST_PATH)\n    zip_ref.close()\nif not os.path.exists('./models'):\n    os.makedirs('./models')\nprint(os.listdir(TRAIN_PATH))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false,"collapsed":true},"cell_type":"code","source":"def rle_encoding(x, order='F', to_str=True):\n    dots = np.where(x.flatten(order=order) == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    if to_str:\n        return ' '.join(str(y) for y in run_lengths)\n    return run_lengths\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97717be246b849b59bef737ccf01803c34e9a90e","trusted":false,"collapsed":true},"cell_type":"code","source":"train_csv = pd.read_csv(TRAIN_CSV)\ndepth_csv = pd.read_csv(DEPTH_CSV)\ntest_csv = depth_csv[~depth_csv.index.isin(train_csv.index)]\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"442d1aace9485e3ac96df68ed6ccf52b2a789682","trusted":false,"collapsed":true},"cell_type":"code","source":"X_train = []\nY_train = [] \n\nprint('Getting train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm(enumerate(train_csv.id), total=len(train_csv.id)):\n    path = TRAIN_PATH\n    img = imread(path + 'images/' + id_ + '.png')[...,0].astype(np.uint8)\n    assert img.ndim==2\n    assert img.shape[0]==ORI_D and img.shape[1]==ORI_D\n    X_train.append(img)\n    mask = np.squeeze(imread(path + 'masks/' + id_ + '.png')>0).astype(np.uint8)\n    assert mask.ndim==2\n    Y_train.append(mask)\ndel img, mask\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31e3c071c70c4a0aab1af76afb4b02ea81ea70ff","trusted":false,"collapsed":true},"cell_type":"code","source":"# Check if training data looks all right\nix = np.random.randint(0, len(train_csv.id))\nplt.imshow(X_train[ix], cmap='gray')\nplt.show()\nplt.imshow(Y_train[ix], cmap='gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"4f46341151e3af79360505f78baf46f1de17d3aa"},"cell_type":"code","source":"def custom_loss(y_true, y_pred_):\n    \n    y_pred = K.sigmoid(y_pred_)\n    \n    def dice_coef(y_true, y_pred): \n        return (2.* K.sum(y_true*y_pred) + 1) / (K.sum(y_true) + K.sum(y_pred) + 1) # scaler\n    \n    s_dice_coef = dice_coef(y_true, y_pred) # scaler\n    s_bce = K.mean(K.binary_crossentropy(y_true, y_pred)) # scaler\n    loss = 0.5*s_bce - s_dice_coef + 1. # scaler [0, inf)\n    \n    return loss # scaler [0, inf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"517ef474f1dc3cb3747889f6d48a0cfebb00a63e","trusted":false,"collapsed":true},"cell_type":"code","source":"# Define IoU metric\ndef score_numpy(Ys, Ps, th=0.0):\n    iou_ths = np.arange(0.0, 1.0, 0.05)\n    Ps = Ps.reshape(Ps.shape[0], -1).copy()\n    Ys = Ys.reshape(Ys.shape[0], -1).copy()\n    for n, P in enumerate(Ps):\n        Ps[n] = P>th\n    Ps = Ps.astype(np.bool)\n    Ys = Ys.astype(np.bool)\n    TPs = np.zeros_like(iou_ths, dtype=np.float32)\n    FPs = np.zeros_like(iou_ths, dtype=np.float32)\n    FNs = np.zeros_like(iou_ths, dtype=np.float32)\n    for Y, P in zip(Ys, Ps):\n        iou = (Y&P).sum() / ((Y|P).sum()+1e-9)\n        Y_sum = Y.sum()\n        P_sum = P.sum()\n        for n, iou_th in enumerate(iou_ths):\n            if iou>=iou_th: # TP\n                TPs[n]+=1\n            elif Y_sum<=0 and P_sum>0: # FP\n                FPs[n]+=1\n            elif Y_sum>0 and P_sum<=0: # FN\n                FNs[n]+=1\n    return np.mean(TPs / (TPs+FPs+FNs+1e-9))\n\ndef score(label, pred):\n    metric_value = tf.py_func(score_numpy, [label, pred], tf.float32)\n    return metric_value","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"36b05fd69448526c42a023b231832a2ffd761d52"},"cell_type":"code","source":"# code download from: https://github.com/bermanmaxim/LovaszSoftmax\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    gts = tf.reduce_sum(gt_sorted)\n    intersection = gts - tf.cumsum(gt_sorted)\n    union = gts + tf.cumsum(1. - gt_sorted)\n    jaccard = 1. - intersection / (union+1e-9)\n    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n    return jaccard\n\n\n# --------------------------- BINARY LOSSES ---------------------------\n\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        def treat_image(log_lab):\n            log, lab = log_lab\n            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n            log, lab = flatten_binary_scores(log, lab, ignore)\n            return lovasz_hinge_flat(log, lab)\n        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n        loss = tf.reduce_mean(losses)\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n\n    def compute_loss():\n        labelsf = tf.cast(labels, logits.dtype)\n        signs = 2. * labelsf - 1.\n        errors = 1. - logits * tf.stop_gradient(signs)\n        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n        gt_sorted = tf.gather(labelsf, perm)\n        grad = lovasz_grad(gt_sorted)\n        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n        return loss\n\n    # deal with the void prediction case (only void pixels)\n    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n                   lambda: tf.reduce_sum(logits) * 0.,\n                   compute_loss,\n                   strict=True,\n                   name=\"loss\"\n                   )\n    return loss\n\n\ndef flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = tf.reshape(scores, (-1,))\n    labels = tf.reshape(labels, (-1,))\n    if ignore is None:\n        return scores, labels\n    valid = tf.not_equal(labels, ignore)\n    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n    return vscores, vlabels\n\ndef lovasz_loss(y_true, y_pred):\n    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n    #logits = K.log(y_pred / (1. - y_pred))\n    logits = y_pred #Jiaxin\n    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n    return loss","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3da5c711e29eca551ddd2073b48e73cb9ca170e5","trusted":false,"collapsed":true},"cell_type":"code","source":"def build_model():\n    def conv(f, k=3, act='relu'):\n        return Conv2D(f, (k, k), activation=act, kernel_initializer='he_normal', padding='same')\n    def _res_conv(inputs, f, k=3): # very simple residual module\n        channels = int(inputs.shape[-1])\n        \n        cs = inputs\n        \n        cs = BatchNormalization() (cs)\n        cs = Activation('relu') (cs)\n        cs = conv(f, 3, act=None) (cs)\n        \n        cs = Dropout(0.1) (cs)\n        \n        cs = BatchNormalization() (cs)\n        cs = Activation('relu') (cs)\n        cs = conv(f, 3, act=None) (cs)\n        \n        if f!=channels:\n            t1 = conv(f, 1, None) (inputs) # identity mapping\n        else:\n            t1 = inputs\n        \n        out = Add()([t1, cs]) # t1 + c2\n        return out\n    def pool():\n        return MaxPooling2D((2, 2))\n    def up(inputs, pad='same'):\n        upsampled = Conv2DTranspose(int(inputs.shape[-1]), (3, 3), strides=(2, 2), kernel_initializer='he_normal', padding=pad) (inputs)\n        return upsampled\n    \n    inputs = Input(shape=(ORI_D, ORI_D, 1))\n    preprocess1 = Lambda(lambda x: x/127.5-1.0) (inputs)\n    \n    r = 16\n    rep = 4\n    mid_rep = 3\n    x = preprocess1\n    \n    skip_connections = []\n    pad_mode = ['same', 'valid', 'same', 'valid']\n    \n    for t in range(rep):\n        x = conv(r*int(2**t), 3, None) (x)\n        x = _res_conv(x, r*int(2**t), 3)\n        x = _res_conv(x, r*int(2**t), 3)\n        x = BatchNormalization() (x)\n        x = Activation('relu') (x)\n        skip_connections.append(x)\n        x = pool() (x)\n    \n    x = conv(r*int(2**rep), 3, None) (x)\n    for t in range(mid_rep):\n        x = _res_conv(x, r*int(2**rep))\n    \n    for t, s, p in zip(reversed(range(rep)), reversed(skip_connections), pad_mode):\n        x = BatchNormalization() (x)\n        x = Activation('relu') (x)\n        x = up(x, p)\n        x = concatenate([s, x])\n        x = conv(r*int(2**t), 3, None) (x)\n        x = _res_conv(x, r*int(2**t), 3)\n        x = _res_conv(x, r*int(2**t), 3)\n    x = BatchNormalization() (x)\n    x = Activation('relu') (x)\n    outputs = Conv2D(1, (1, 1), activation=None, kernel_initializer='he_normal', padding='valid') (x)\n    return Model([inputs], [outputs])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc9e9a58f40628de5fe39c6c5863106ec6824cbd","trusted":false,"collapsed":true},"cell_type":"code","source":"model = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b013db1b18b798066e620c8a6dd27e632c6be657","trusted":false,"collapsed":true},"cell_type":"code","source":"from keras.utils import Sequence\nimport cv2\nfrom sklearn.utils import shuffle\nfrom skimage.transform import AffineTransform, warp\nimport copy\nimport imgaug as ia\nfrom imgaug import augmenters as iaa\n\nclass data_generator(Sequence):\n    def __init__(self, data, label, batch_size=4, training=True, shuffle=True):\n        self.data = data\n        self.label= label\n        self.batch_size = batch_size\n        self.training = training\n        self.shuffle = shuffle\n        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n        self.seq_color = iaa.SaltAndPepper((0.01, 0.05))\n        self.distortion = iaa.Sequential([\n                sometimes(iaa.Affine(\n                    rotate=(-5, 5), # rotate by -45 to +45 degrees\n                    order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n                    cval=0, # if mode is constant, use a cval between 0 and 255\n                    mode='constant' # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n                )),\n                iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05)),\n                sometimes(iaa.ElasticTransformation(alpha=(0.01, 0.4), sigma=0.2)),\n                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.02)))\n            ], random_order=True)\n    def __len__(self):\n        return int(np.ceil(float(len(self.data))/self.batch_size))\n    def on_epoch_end(self):\n        if self.shuffle: self.data, self.label = shuffle(self.data, self.label)\n    def __getitem__(self, i):\n        l_bound =  i    * self.batch_size\n        r_bound = (i+1) * self.batch_size\n        if r_bound>len(self.data): # ensure every iteration has the same batch size\n            r_bound = len(self.data)\n            l_bound = r_bound - self.batch_size\n        dat_que = np.empty((self.batch_size, ORI_D, ORI_D, 1), dtype=np.uint8)\n        lab_que = np.empty((self.batch_size, ORI_D, ORI_D, 1), dtype=np.uint8)\n        for n, index in enumerate(range(l_bound, r_bound)):\n            img = copy.deepcopy(self.data[index]).astype(np.float32) / 255.\n            lab = copy.deepcopy(self.label[index]).astype(np.float32)\n            if self.training:\n                if np.random.rand() < .5: # flip horizontal\n                    img = np.flip(img, 1)\n                    lab = np.flip(lab, 1)\n\n                if np.random.rand()<0.4:\n                    a = .05 # amptitude\n                    t  = np.random.uniform(1-a,1+a)\n                    img = np.clip(img * t, 0, 1) \n                \n                if np.random.rand()<0.3:\n                    sigma = np.random.rand()*0.03\n                    img = np.clip(img + np.random.randn(*img.shape)*sigma, 0, 1)\n                \n                if np.random.rand() < 0.3:\n                    img = np.clip(self.seq_color.augment_image(img), 0, 1)\n                if np.random.rand() < 0.3:\n                    det = self.distortion.to_deterministic()\n                    img = np.clip(det.augment_image(img), 0, 1)\n                    lab = np.clip(det.augment_image(lab), 0, 1)\n                if np.random.rand() < 0.1:\n                    img = cv2.GaussianBlur(img, (3, 3), 0)\n                \n                if np.random.rand() < 0.3:\n                    crop_ratio = np.random.uniform(0.01, 0.1, size=4)\n                    u, r, d, l = np.round(crop_ratio * np.array([img.shape[0], img.shape[1]]*2)).astype(np.uint8)\n                    img = img[u:-d,l:-r] # crop image\n                    lab = lab[u:-d,l:-r] # crop image\n            ### end of data augmentation ###\n\n            img = np.clip(img.astype(np.float32)*255,0, 255).astype(np.uint8)\n            lab = np.round(np.clip(lab.astype(np.float32),0, 1)).astype(np.uint8)\n            \n            if img.shape[0]!=ORI_D or img.shape[1]!=ORI_D:\n                diffr = ORI_D-img.shape[0] # must >= 0\n                diffc = ORI_D-img.shape[1] # must >= 0\n                padr1 = np.random.randint(diffr+1)\n                padr2 = diffr-padr1\n                padc1 = np.random.randint(diffc+1)\n                padc2 = diffc-padc1\n                if np.random.rand() < 0.4:\n                    img = np.pad(img, ((padr1,padr2),(padc1,padc2)), 'wrap')\n                    lab = np.pad(lab, ((padr1,padr2),(padc1,padc2)), 'wrap')\n                else:\n                    img = np.pad(img, ((padr1,padr2),(padc1,padc2)), 'constant', constant_values=np.random.randint(7))\n                    lab = np.pad(lab, ((padr1,padr2),(padc1,padc2)), 'constant', constant_values=0)\n\n            dat_que[n,...,0] = img\n            lab_que[n,...,0] = lab\n        return dat_que, lab_que","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51c194e76cb244dd8078d938bbbe9e6d755f9852","trusted":false,"collapsed":true},"cell_type":"code","source":"import bisect\nN_BINS = 10\ncoverage = np.asarray([ x.sum() / (ORI_D**2) for x in Y_train ])\ncoverage_lev = np.linspace(0, 1, N_BINS)\ndepth_lev = np.linspace(np.min(depth_csv.z), np.max(depth_csv.z), N_BINS)\nstratify = []\nfor cov, z in zip(coverage, depth_csv.z):\n    cov_idx = bisect.bisect_left(coverage_lev, cov)\n    z_idx = bisect.bisect_left(depth_lev, z)\n    stratify.append(np.array([cov_idx, z_idx], dtype=np.int32))\nstratify = np.asarray(stratify, dtype=np.int32)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5ad69f17ffddb9850d8b03b71de596ec15d4f6a","trusted":false,"collapsed":true},"cell_type":"code","source":"# https://www.surveysystem.com/sscalc.htm\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=2000, shuffle=True, stratify = stratify)\ndel coverage, coverage_lev, stratify","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a95cbcbf8217be038ed18f2d74f40995f289471","trusted":false,"collapsed":true},"cell_type":"code","source":"train_generator = data_generator(X_train, Y_train, batch_size=BS, training=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"5e71eabf61b220d00aa44cae285b7b96276cf2bb"},"cell_type":"code","source":"import multiprocessing\nfrom keras.optimizers import Adam\ncheckpointer_best = ModelCheckpoint('./models/best.h5', monitor='val_score', mode='max', verbose=1, save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f99df4a2778bece3c43cff8ed0ec86e5ebb88353","scrolled":false,"trusted":false,"collapsed":true},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8,\n                              patience=2, min_lr=0.00001, mode='min')\n# early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=10)\nmodel.compile(loss=custom_loss, optimizer=Adam(lr=0.001), metrics=[score])\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch= len(train_generator), \n                              epochs=EPOCHS_1, \n                              validation_data=(np.asarray(X_val)[...,np.newaxis], np.asarray(Y_val)[...,np.newaxis]), \n                              callbacks=[checkpointer_best, reduce_lr],\n                              workers= max(1, multiprocessing.cpu_count()-3),\n                              use_multiprocessing= True,\n                              shuffle = True\n                              )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db6cbe8675e22e6e44a025b77e19c126bb85bb7c","trusted":false,"collapsed":true},"cell_type":"code","source":"plt.plot(history.history['score'])\nplt.plot(history.history['val_score'])\nplt.title('LB')\nplt.ylabel('LB @threshold=0.0')\nplt.xlabel('epoch')\nplt.legend(['train','valid'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d451e568a32cef6dda0998e973f27246ce63c3f","trusted":false,"collapsed":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','valid'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f99df4a2778bece3c43cff8ed0ec86e5ebb88353","scrolled":false,"trusted":false,"collapsed":true},"cell_type":"code","source":"model.load_weights('./models/best.h5')\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8,\n                              patience=2, min_lr=0.00001, mode='min')\n# early_stop = EarlyStopping(monitor='val_loss', mode='min', patience=10)\nmodel.compile(loss=lovasz_loss, optimizer=Adam(lr=0.001), metrics=[score])\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch= len(train_generator), \n                              epochs=EPOCHS_2, \n                              validation_data=(np.asarray(X_val)[...,np.newaxis], np.asarray(Y_val)[...,np.newaxis]), \n                              callbacks=[checkpointer_best, reduce_lr],\n                              workers= max(1, multiprocessing.cpu_count()-3),\n                              use_multiprocessing= True,\n                              shuffle = True\n                              )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db6cbe8675e22e6e44a025b77e19c126bb85bb7c","trusted":false,"collapsed":true},"cell_type":"code","source":"plt.plot(history.history['score'])\nplt.plot(history.history['val_score'])\nplt.title('LB')\nplt.ylabel('LB @threshold=0.0')\nplt.xlabel('epoch')\nplt.legend(['train','valid'], loc='lower right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d451e568a32cef6dda0998e973f27246ce63c3f","trusted":false,"collapsed":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','valid'], loc='upper right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97ee307d7e91d2eb524ac99ec9374f7129ccb44d","trusted":false,"collapsed":true},"cell_type":"code","source":"model.load_weights('./models/best.h5')\npreds_val = model.predict(np.asarray(X_val)[...,np.newaxis], batch_size=BS, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"620052597a7da1a92e65ab5ec8d3354dad30e8ae","trusted":false,"collapsed":true},"cell_type":"code","source":"threshold_choices = np.linspace(-0.1, 0.1, 200)\nbest_threshold = 0.1\nbest_score = 0\n\nfor th in threshold_choices:\n    Ys = np.squeeze(Y_val)\n    Ps = np.squeeze(preds_val)\n    score = score_numpy(Ys, Ps, th)\n    #print('score: {:.4f} @threshold: {:.2f}'.format(score, th))\n    if score>best_score:\n        best_score = score\n        best_threshold = th\nprint('best threshold: {:.2f}, best score: {:.8f}'.format(best_threshold, best_score))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed98fa3f962d6f6cdfbfd931b7c10f389a89e748","trusted":false,"collapsed":true},"cell_type":"code","source":"# Perform a sanity check on some random training samples\nix = np.random.randint(0, len(preds_val))\nprint(ix)\nshape = Y_val[ix].shape[:2]\nplt.imshow(X_val[ix])\nplt.show()\nplt.imshow(Y_val[ix])\nplt.show()\npreds = np.squeeze(preds_val[ix])\npreds = preds>best_threshold\nplt.imshow(preds)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"449bd482588ee8ca55b59c27a65a592dc7fcf194","trusted":false,"collapsed":true},"cell_type":"code","source":"del X_train, Y_train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a50953a32d052779987dd3214b6802bd275235d","trusted":false,"collapsed":true},"cell_type":"code","source":"sub_rles = []\nx_test = []\nprint('Reading testing data...')\nfor n, id_ in tqdm(enumerate(test_csv.id), total=len(test_csv.id)):\n    path = TEST_PATH\n    img = imread(path + 'images/' + id_ + '.png')[...,0].astype(np.uint8)[...,np.newaxis]\n    x_test.append(img)\n\nprint('Predicting...')\npreds = model.predict(np.asarray(x_test), batch_size=BS, verbose=1)[...,0]\nprint('Convert to RLE...')\nfor pred in tqdm(preds, total=len(preds)):\n    pred_thresholded = (pred>best_threshold).astype(np.bool)\n    rle = rle_encoding(pred_thresholded)\n    sub_rles.append(rle)\nsub = pd.DataFrame()\nsub['id'] = test_csv.id\nsub['rle_mask'] = sub_rles\nsub.to_csv('salty.csv', index=False)\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"299f55847c6de7fdb8837ecc5996b62708cdab42","trusted":false,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}