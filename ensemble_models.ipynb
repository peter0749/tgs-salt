{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e61ef2d8-f315-4f7f-b07e-1de0f4e8441a",
    "_uuid": "1677fddbb95f7545b6540e9201f3339a0fdbfc5d"
   },
   "source": [
    "# Intro\n",
    "Hello! This rather quick and dirty kernel shows how to get started on segmenting nuclei using a neural network in Keras. \n",
    "\n",
    "The architecture used is the so-called [U-Net](https://arxiv.org/abs/1505.04597), which is very common for image segmentation problems such as this. I believe they also have a tendency to work quite well even on small datasets.\n",
    "\n",
    "Let's get started importing everything we need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "c332549b-8d23-4bb5-8497-e7a8eb8b21d2",
    "_uuid": "5c38504af3a84bee68c66d3cde74443c58df422f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/anaconda3/envs/dnn/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "TEST_PATH = '/media/peter/DATA/stage2_test_final/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "ffa0caf0-2d1b-40f2-865b-8e6db88526b6",
    "_uuid": "3fb9d6530fbbd0e22e41fc4fd9fd9fc0bff027ac"
   },
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ids = train_ids[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "ca0cc34b-c26f-41ee-88d7-975aebdb634e",
    "_uuid": "9e389ba8bdb5b6fc03b231b6a6c84a8bde634053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3019/3019 [00:32<00:00, 92.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from skimage.draw import circle\n",
    "from skimage.color import gray2rgb\n",
    "import math\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png', as_grey=False)\n",
    "    if img.ndim==2: img = gray2rgb(img)\n",
    "    img = img[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append(img.shape[:2])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "c1dbc57c-b497-4ccb-b077-2053203ab7ed",
    "_uuid": "0aa97d66c29f45dfac9b0f45fcf74ba0e778ba5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 [(None, 256, 256, 3) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 256, 256, 3)  31522694    model_1[1][0]                    \n",
      "                                                                 model_1[1][1]                    \n",
      "                                                                 model_1[1][2]                    \n",
      "                                                                 model_1[1][3]                    \n",
      "==================================================================================================\n",
      "Total params: 31,522,694\n",
      "Trainable params: 31,522,694\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Lambda, Add, Activation, UpSampling2D, Dropout, Average\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.metrics import binary_accuracy\n",
    "\n",
    "MODELS_DIR = '/media/peter/DATA/model_to_ensemble'\n",
    "\n",
    "def ensemble(models):\n",
    "    model_input = Input(shape=(IMG_HEIGHT, IMG_HEIGHT, IMG_CHANNELS))\n",
    "    input_branchs = [Dropout(0)(model_input) for _ in range(len(models))]\n",
    "    input_model = Model([model_input], input_branchs)\n",
    "    model_outputs = []\n",
    "    input_ = [Input(shape=(IMG_HEIGHT, IMG_HEIGHT, IMG_CHANNELS), name='t_input_c_%d'%n) for n in range(len(models))]\n",
    "    for n, (input_l, model) in enumerate(zip(input_, models)):\n",
    "        model.name = 'ensemble_t_output_%d'%n\n",
    "        model_outputs.append(model(input_l))\n",
    "    ensemble_m_output = Average() (model_outputs)\n",
    "    ensemble_t_model = Model(input_, [ensemble_m_output])\n",
    "    ensemble_s_output = ensemble_t_model(input_model(model_input))\n",
    "    return Model([model_input], [ensemble_s_output], name='ensemble')\n",
    "            \n",
    "models = [load_model(model_name, custom_objects={'mean_iou': binary_accuracy, 'custom_loss': mean_squared_error, 'mean_iou_marker': binary_accuracy}) for model_name in glob.glob(MODELS_DIR+'/*.h5')]\n",
    "model = ensemble(models)\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error') # need to compile\n",
    "model.summary()\n",
    "model.save('ensemble.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.transform import AffineTransform, warp\n",
    "import copy\n",
    "\n",
    "BS=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "2daa48d5-ac98-4e18-af3f-a582baaa44f0",
    "_uuid": "f841760b4abca1a25cb750822f88268bd79bf2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3019/3019 [==============================] - 350s 116ms/step\n"
     ]
    }
   ],
   "source": [
    "from skimage.morphology import closing, square, remove_small_objects\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "# Predict on testing set\n",
    "preds_test = model.predict(X_test, verbose=1, batch_size=BS)\n",
    "preds_test, preds_test_marker, preds_test_dt = np.transpose(preds_test, (3,0,1,2))\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append((resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True),\n",
    "                                 resize(np.squeeze(preds_test_marker[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True),\n",
    "                                 resize(np.squeeze(preds_test_dt[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True)\n",
    "                                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "59a0af60-a7d7-41ef-a6fe-9e3c72defa07",
    "_uuid": "4f99c1bf852e82b60bd4f982ca0df293f712cdf0"
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import watershed\n",
    "\n",
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def lb(image, marker, distance):\n",
    "    if np.sum(image) < np.sum(marker):\n",
    "        image = marker\n",
    "    else:\n",
    "        marker = np.array((marker==1) & (image==1))\n",
    "    markers = ndi.label(marker)[0]\n",
    "    labels = watershed(-distance, markers, mask=image)\n",
    "    if np.sum(labels) == 0:\n",
    "        labels[0,0] = 1\n",
    "    return labels\n",
    "\n",
    "def prob_to_rles(x, marker, dt):\n",
    "    x_thres = threshold_otsu(x)\n",
    "    marker_thres = threshold_otsu(marker)\n",
    "    lab_img = lb(x > x_thres, marker > marker_thres, dt)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "22fe24a1-7659-4cc9-9d23-211f38e5b99f",
    "_uuid": "089587843ed6a3955fdcb9b23a6ec3bf5d703688"
   },
   "outputs": [],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(*preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "1ba0ee3a-cca0-4349-83f6-09a1ac6fcb44",
    "_uuid": "ba589f56f5be1e6886bc88f5bf9e7d0a408e4048"
   },
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.to_csv('sub-dsbowl2018-ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
